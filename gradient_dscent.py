# -*- coding: utf-8 -*-
"""Gradient Dscent.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BaBTWr1jRH-QUY4_DbowXQ9Y5TrN7PpY
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import tensorflow as tf
from tensorflow import keras
import pandas as pd
from matplotlib import pyplot as plt
# %matplotlib inline

df = pd.read_csv("/insurance_data.csv")
df.head(10)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df[['age','affordibility']],df.bought_insurance,test_size=0.2, random_state=25)

X_train.shape

X_train_scale = X_train.copy()

X_train_scale["age"] = X_train_scale["age"]/100

X_test_scale = X_test.copy()

X_test_scale["age"] = X_test_scale["age"]/100

model = keras.Sequential([

    keras.layers.Dense(1, input_shape = (2,),activation = "sigmoid",kernel_initializer = "ones", bias_initializer = "zeros"),


])


model.compile(
    optimizer = "adam",
    loss = "binary_crossentropy",
    metrics = ["accuracy"]
)

model.fit(X_test_scale,y_test,epochs = 5000)

model.evaluate(X_test_scale,y_test)

coef, intercept = model.get_weights()
coef, intercept

"""# **Neural Network from Scratch**

"""

def sigmoid(x):
        import math
        return 1 / (1 + math.exp(-x))
sigmoid(18)

def prediction_function(age, affordibility):
    weighted_sum = coef[0]*age + coef[1]*affordibility + intercept
    return sigmoid(weighted_sum)

prediction_function(.47, 1)

def sigmoid_numpy(X):
   return 1/(1+np.exp(-X))

sigmoid_numpy(np.array([12,0,1]))

def log_loss(y_true, y_predicted):
    epsilon = 1e-15
    y_predicted_new = [max(i,epsilon) for i in y_predicted]
    y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]
    y_predicted_new = np.array(y_predicted_new)
    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))

def gradient_descent(age, affordability, y_true, epochs, loss_thresold):
    w1 = w2 = 1
    bias = 0
    rate = 0.5
    n = len(age)
    for i in range(epochs):

        print("##############################")
        weighted_sum = w1 * age + w2 * affordability + bias
        y_predicted = sigmoid_numpy(weighted_sum)
        loss = log_loss(y_true, y_predicted)
        print("loss",loss)
        w1d = (1/n)*np.dot(np.transpose(age),(y_predicted-y_true))
        print("w1d",w1d)
        w2d = (1/n)*np.dot(np.transpose(affordability),(y_predicted-y_true))
        print("w2d",w2d)

        bias_d = np.mean(y_predicted-y_true)
        w1 = w1 - rate * w1d
        w2 = w2 - rate * w2d
        bias = bias - rate * bias_d

        print (f'Epoch:{i}, w1:{w1}, w2:{w2}, bias:{bias}, loss:{loss}')

        if loss<=loss_thresold:
            break

    return w1, w2, bias

gradient_descent(X_train_scale['age'],X_train_scale['affordibility'],y_train,1000, 0.4631)